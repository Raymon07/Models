{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d528a23",
   "metadata": {},
   "source": [
    "##  PREDICTING THE LINKS BETWEEN RESEARCH PAPERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96400f42",
   "metadata": {},
   "source": [
    "###  installing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c21ee2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arxiv in c:\\users\\antoj\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: feedparser in c:\\users\\antoj\\anaconda3\\lib\\site-packages (from arxiv) (6.0.10)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\antoj\\anaconda3\\lib\\site-packages (from feedparser->arxiv) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5266d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: node2vec in c:\\users\\antoj\\anaconda3\\lib\\site-packages (0.4.6)\n",
      "Requirement already satisfied: joblib<2.0.0,>=1.1.0 in c:\\users\\antoj\\anaconda3\\lib\\site-packages (from node2vec) (1.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.19.5 in c:\\users\\antoj\\anaconda3\\lib\\site-packages (from node2vec) (1.20.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.55.1 in c:\\users\\antoj\\anaconda3\\lib\\site-packages (from node2vec) (4.64.1)\n",
      "Requirement already satisfied: gensim<5.0.0,>=4.1.2 in c:\\users\\antoj\\anaconda3\\lib\\site-packages (from node2vec) (4.1.2)\n",
      "Requirement already satisfied: networkx<3.0,>=2.5 in c:\\users\\antoj\\anaconda3\\lib\\site-packages (from node2vec) (2.5)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\antoj\\anaconda3\\lib\\site-packages (from gensim<5.0.0,>=4.1.2->node2vec) (0.29.23)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\antoj\\anaconda3\\lib\\site-packages (from gensim<5.0.0,>=4.1.2->node2vec) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\antoj\\anaconda3\\lib\\site-packages (from gensim<5.0.0,>=4.1.2->node2vec) (1.6.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\antoj\\anaconda3\\lib\\site-packages (from networkx<3.0,>=2.5->node2vec) (5.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\antoj\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.55.1->node2vec) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install node2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ac0565",
   "metadata": {},
   "source": [
    "### collecting research papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c78b1cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(647, 8)\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arxiv\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, confusion_matrix, classification_report\n",
    "from itertools import product\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from node2vec import Node2Vec as n2v\n",
    "\n",
    "# constants\n",
    "queries = [\n",
    "    'automl', 'machinelearning', 'data', 'phyiscs','mathematics', 'recommendation system', 'nlp', 'neural networks'\n",
    "]\n",
    "\n",
    "def search_arxiv(queries, max_results = 100):\n",
    "    '''\n",
    "    This function will search arxiv associated to a set of queries and store\n",
    "    the latest 10000 (max_results) associated to that search.\n",
    "    \n",
    "    params:\n",
    "        queries (List -> Str) : A list of strings containing keywords you want\n",
    "                                to search on Arxiv\n",
    "        max_results (Int) : The maximum number of results you want to see associated\n",
    "                            to your search. Default value is 1000, capped at 300000\n",
    "                            \n",
    "    returns:\n",
    "        This function will return a DataFrame holding the following columns associated\n",
    "        to the queries the user has passed. \n",
    "            `title`, `date`, `article_id`, `url`, `main_topic`, `all_topics`\n",
    "    \n",
    "    example:\n",
    "        research_df = search_arxiv(\n",
    "            queries = ['automl', 'recommender system', 'nlp', 'data science'],\n",
    "            max_results = 10000\n",
    "        )\n",
    "    '''\n",
    "    d = []\n",
    "    searches = []\n",
    "    # hitting the API\n",
    "    for query in queries:\n",
    "        search = arxiv.Search(\n",
    "          query = query,\n",
    "          max_results = max_results,\n",
    "          sort_by = arxiv.SortCriterion.SubmittedDate,\n",
    "          sort_order = arxiv.SortOrder.Descending\n",
    "        )\n",
    "        searches.append(search)\n",
    "    \n",
    "    # Converting search result into df\n",
    "    for search in searches:\n",
    "        for res in search.results():\n",
    "            data = {\n",
    "                'title' : res.title,\n",
    "                'date' : res.published,\n",
    "                'article_id' : res.entry_id,\n",
    "                'url' : res.pdf_url,\n",
    "                'main_topic' : res.primary_category,\n",
    "                'all_topics' : res.categories,\n",
    "                'authors' : res.authors\n",
    "            }\n",
    "            d.append(data)\n",
    "        \n",
    "    d = pd.DataFrame(d)\n",
    "    d['year'] = pd.DatetimeIndex(d['date']).year\n",
    "    \n",
    "    # change article id from url to integer\n",
    "    unique_article_ids = d.article_id.unique()\n",
    "    article_mapping = {art:idx for idx,art in enumerate(unique_article_ids)}\n",
    "    d['article_id'] = d['article_id'].map(article_mapping)\n",
    "    return d\n",
    "  \n",
    "research_df = search_arxiv(\n",
    "    queries = queries,\n",
    "    max_results = 100\n",
    ")\n",
    "print(research_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "174864ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>article_id</th>\n",
       "      <th>url</th>\n",
       "      <th>main_topic</th>\n",
       "      <th>all_topics</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Automated Imbalanced Learning</td>\n",
       "      <td>2022-11-01 10:43:48+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>http://arxiv.org/pdf/2211.00376v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>[cs.LG, cs.AI]</td>\n",
       "      <td>[Prabhant Singh, Joaquin Vanschoren]</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Efficient Automatic Machine Learning via Desig...</td>\n",
       "      <td>2022-10-21 21:25:59+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>http://arxiv.org/pdf/2210.12257v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>[cs.LG, cs.AI]</td>\n",
       "      <td>[Shirley Wu, Jiaxuan You, Jure Leskovec, Rex Y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Side of AutoML: Towards Architectural...</td>\n",
       "      <td>2022-10-21 18:13:23+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>http://arxiv.org/pdf/2210.12179v1</td>\n",
       "      <td>cs.CR</td>\n",
       "      <td>[cs.CR, cs.LG]</td>\n",
       "      <td>[Ren Pang, Changjiang Li, Zhaohan Xi, Shouling...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extensible Proxy for Efficient NAS</td>\n",
       "      <td>2022-10-17 22:18:22+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>http://arxiv.org/pdf/2210.09459v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>[cs.LG, cs.AI, cs.CV]</td>\n",
       "      <td>[Yuhong Li, Jiajie Li, Cong Han, Pan Li, Jinju...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multi-Agent Automated Machine Learning</td>\n",
       "      <td>2022-10-17 13:32:59+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>http://arxiv.org/pdf/2210.09084v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>[cs.LG, cs.CV]</td>\n",
       "      <td>[Zhaozhi Wang, Kefan Su, Jian Zhang, Huizhu Ji...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>A 5G Enabled Adaptive Computing Workflow for G...</td>\n",
       "      <td>2022-10-31 21:27:36+00:00</td>\n",
       "      <td>560</td>\n",
       "      <td>http://arxiv.org/pdf/2211.00150v1</td>\n",
       "      <td>eess.SY</td>\n",
       "      <td>[eess.SY, cs.SY]</td>\n",
       "      <td>[Yousu Chen, Liwei Wang, Xiaoyuan Fan, Dexin W...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>A Machine Learning Tutorial for Operational Me...</td>\n",
       "      <td>2022-10-31 21:10:48+00:00</td>\n",
       "      <td>561</td>\n",
       "      <td>http://arxiv.org/pdf/2211.00147v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>[cs.LG, cs.CV, physics.ao-ph]</td>\n",
       "      <td>[Randy J. Chase, David R. Harrison, Gary Lackm...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>Reconfigurable nonlinear optical element using...</td>\n",
       "      <td>2022-10-31 20:51:24+00:00</td>\n",
       "      <td>562</td>\n",
       "      <td>http://arxiv.org/pdf/2211.00136v1</td>\n",
       "      <td>physics.optics</td>\n",
       "      <td>[physics.optics, physics.app-ph]</td>\n",
       "      <td>[Vahid Nikkhah, Mario Junior Mencagli, Nader E...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>A New Concept of the Value Function</td>\n",
       "      <td>2022-10-31 20:43:00+00:00</td>\n",
       "      <td>563</td>\n",
       "      <td>http://arxiv.org/pdf/2211.00131v1</td>\n",
       "      <td>econ.GN</td>\n",
       "      <td>[econ.GN, q-fin.EC]</td>\n",
       "      <td>[Kazuo Sano]</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>SIMPLE-RC: Group Network Inference with Non-Sh...</td>\n",
       "      <td>2022-10-31 20:36:24+00:00</td>\n",
       "      <td>564</td>\n",
       "      <td>http://arxiv.org/pdf/2211.00128v1</td>\n",
       "      <td>stat.ML</td>\n",
       "      <td>[stat.ML, cs.LG, math.ST, stat.ME, stat.TH]</td>\n",
       "      <td>[Jianqing Fan, Yingying Fan, Jinchi Lv, Fan Yang]</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>647 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0                        Automated Imbalanced Learning   \n",
       "1    Efficient Automatic Machine Learning via Desig...   \n",
       "2    The Dark Side of AutoML: Towards Architectural...   \n",
       "3                   Extensible Proxy for Efficient NAS   \n",
       "4               Multi-Agent Automated Machine Learning   \n",
       "..                                                 ...   \n",
       "642  A 5G Enabled Adaptive Computing Workflow for G...   \n",
       "643  A Machine Learning Tutorial for Operational Me...   \n",
       "644  Reconfigurable nonlinear optical element using...   \n",
       "645                A New Concept of the Value Function   \n",
       "646  SIMPLE-RC: Group Network Inference with Non-Sh...   \n",
       "\n",
       "                         date  article_id                                url  \\\n",
       "0   2022-11-01 10:43:48+00:00           0  http://arxiv.org/pdf/2211.00376v1   \n",
       "1   2022-10-21 21:25:59+00:00           1  http://arxiv.org/pdf/2210.12257v1   \n",
       "2   2022-10-21 18:13:23+00:00           2  http://arxiv.org/pdf/2210.12179v1   \n",
       "3   2022-10-17 22:18:22+00:00           3  http://arxiv.org/pdf/2210.09459v1   \n",
       "4   2022-10-17 13:32:59+00:00           4  http://arxiv.org/pdf/2210.09084v1   \n",
       "..                        ...         ...                                ...   \n",
       "642 2022-10-31 21:27:36+00:00         560  http://arxiv.org/pdf/2211.00150v1   \n",
       "643 2022-10-31 21:10:48+00:00         561  http://arxiv.org/pdf/2211.00147v1   \n",
       "644 2022-10-31 20:51:24+00:00         562  http://arxiv.org/pdf/2211.00136v1   \n",
       "645 2022-10-31 20:43:00+00:00         563  http://arxiv.org/pdf/2211.00131v1   \n",
       "646 2022-10-31 20:36:24+00:00         564  http://arxiv.org/pdf/2211.00128v1   \n",
       "\n",
       "         main_topic                                   all_topics  \\\n",
       "0             cs.LG                               [cs.LG, cs.AI]   \n",
       "1             cs.LG                               [cs.LG, cs.AI]   \n",
       "2             cs.CR                               [cs.CR, cs.LG]   \n",
       "3             cs.LG                        [cs.LG, cs.AI, cs.CV]   \n",
       "4             cs.LG                               [cs.LG, cs.CV]   \n",
       "..              ...                                          ...   \n",
       "642         eess.SY                             [eess.SY, cs.SY]   \n",
       "643           cs.LG                [cs.LG, cs.CV, physics.ao-ph]   \n",
       "644  physics.optics             [physics.optics, physics.app-ph]   \n",
       "645         econ.GN                          [econ.GN, q-fin.EC]   \n",
       "646         stat.ML  [stat.ML, cs.LG, math.ST, stat.ME, stat.TH]   \n",
       "\n",
       "                                               authors  year  \n",
       "0                 [Prabhant Singh, Joaquin Vanschoren]  2022  \n",
       "1    [Shirley Wu, Jiaxuan You, Jure Leskovec, Rex Y...  2022  \n",
       "2    [Ren Pang, Changjiang Li, Zhaohan Xi, Shouling...  2022  \n",
       "3    [Yuhong Li, Jiajie Li, Cong Han, Pan Li, Jinju...  2022  \n",
       "4    [Zhaozhi Wang, Kefan Su, Jian Zhang, Huizhu Ji...  2022  \n",
       "..                                                 ...   ...  \n",
       "642  [Yousu Chen, Liwei Wang, Xiaoyuan Fan, Dexin W...  2022  \n",
       "643  [Randy J. Chase, David R. Harrison, Gary Lackm...  2022  \n",
       "644  [Vahid Nikkhah, Mario Junior Mencagli, Nader E...  2022  \n",
       "645                                       [Kazuo Sano]  2022  \n",
       "646  [Jianqing Fan, Yingying Fan, Jinchi Lv, Fan Yang]  2022  \n",
       "\n",
       "[647 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab4e0b7",
   "metadata": {},
   "source": [
    "\n",
    "###  Creating Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "563a022d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 565\n",
      "Number of edges: 30783\n",
      "Average degree: 108.9664\n"
     ]
    }
   ],
   "source": [
    "def generate_network(df, node_col = 'article_id', edge_col = 'main_topic'):\n",
    "    '''\n",
    "    This function will generate a article to article network given an input DataFrame.\n",
    "    It will do so by creating an edge_dictionary where each key is going to be a node\n",
    "    referenced by unique values in node_col and the values will be a list of other nodes\n",
    "    connected to the key through the edge_col.\n",
    "    \n",
    "    params:\n",
    "        df (DataFrame) : The dataset which holds the node and edge columns\n",
    "        node_col (String) : The column name associated to the nodes of the network\n",
    "        edge_col (String) : The column name associated to the edges of the network\n",
    "        \n",
    "    returns:\n",
    "        A networkx graph corresponding to the input dataset\n",
    "        \n",
    "    example:\n",
    "        generate_network(\n",
    "            research_df,\n",
    "            node_col = 'article_id',\n",
    "            edge_col = 'main_topic'\n",
    "        )\n",
    "    '''\n",
    "    edge_dct = {}\n",
    "    for i,g in df.groupby(node_col):\n",
    "        topics = g[edge_col].unique()\n",
    "        edge_df = df[(df[node_col] != i) & (df[edge_col].isin(topics))]\n",
    "        edges = list(edge_df[node_col].unique())\n",
    "        edge_dct[i] = edges\n",
    "    \n",
    "    # create nx network\n",
    "    g = nx.Graph(edge_dct, create_using = nx.MultiGraph)\n",
    "    return g\n",
    "  \n",
    "all_tp = research_df.explode('all_topics').copy()\n",
    "\n",
    "tp_nx = generate_network(\n",
    "    all_tp, \n",
    "    node_col = 'article_id', \n",
    "    edge_col = 'all_topics'\n",
    ")\n",
    "\n",
    "print(nx.info(tp_nx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c421c128",
   "metadata": {},
   "source": [
    "\n",
    "### Applying Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cda98da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555472de7af3411aa5355fe64c7c2d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/565 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|███████████████████████████████████████████████████████| 10/10 [00:11<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4         5         6   \\\n",
      "0 -0.149058 -0.402597 -0.334330  0.433153  0.066343  0.498890  1.447854   \n",
      "1 -0.150856 -0.355169 -0.376519  0.737697  0.029109  0.635733  1.470077   \n",
      "2  0.779876 -0.384114 -0.467994  0.420550  0.215246  0.292632  1.305728   \n",
      "3 -0.652150 -0.029106  0.415992  0.675087  0.188229  0.565279  1.183562   \n",
      "4 -0.294912  0.008023  0.649466  1.210001  0.262638  0.378264  1.385447   \n",
      "\n",
      "         7         8         9         10        11        12        13  \\\n",
      "0  0.437668  0.681068  0.208751 -0.263348 -1.023139  0.218350 -0.686383   \n",
      "1  0.451108  0.590127  0.017675 -0.504675 -0.944975  0.400907 -0.670767   \n",
      "2  0.279769  0.408319 -0.192753 -0.053831 -0.453482  0.052763 -0.682086   \n",
      "3  0.731556  0.614214  0.436885 -0.160814 -0.432583  0.172820 -0.616740   \n",
      "4  0.915668  0.306889  0.031628  0.015953  0.031025 -0.020863 -0.322636   \n",
      "\n",
      "         14        15  \n",
      "0 -0.073022  0.544622  \n",
      "1 -0.357767  0.358673  \n",
      "2 -0.357404  0.624114  \n",
      "3 -0.061100  1.072263  \n",
      "4 -0.227318  1.336323  \n"
     ]
    }
   ],
   "source": [
    "g_emb = n2v(tp_nx, dimensions=16)\n",
    "\n",
    "WINDOW = 1 # Node2Vec fit window\n",
    "MIN_COUNT = 1 # Node2Vec min. count\n",
    "BATCH_WORDS = 4 # Node2Vec batch words\n",
    "\n",
    "mdl = g_emb.fit(\n",
    "    window=WINDOW,\n",
    "    min_count=MIN_COUNT,\n",
    "    batch_words=BATCH_WORDS\n",
    ")\n",
    "\n",
    "# create embeddings dataframe\n",
    "emb_df = (\n",
    "    pd.DataFrame(\n",
    "        [mdl.wv.get_vector(str(n)) for n in tp_nx.nodes()],\n",
    "        index = tp_nx.nodes\n",
    "    )\n",
    ")\n",
    "\n",
    "print(emb_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e3dd38",
   "metadata": {},
   "source": [
    "### create training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e33d527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30783\n"
     ]
    }
   ],
   "source": [
    "unique_nodes = list(tp_nx.nodes())\n",
    "all_possible_edges = [(x,y) for (x,y) in product(unique_nodes, unique_nodes)]\n",
    "\n",
    "# generate edge features for all pairs of nodes\n",
    "edge_features = [\n",
    "    (mdl.wv.get_vector(str(i)) + mdl.wv.get_vector(str(j))) for i,j in all_possible_edges\n",
    "]\n",
    "\n",
    "# get current edges in the network\n",
    "edges = list(tp_nx.edges())\n",
    "\n",
    "# create target list, 1 if the pair exists in the network, 0 otherwise\n",
    "is_con = [1 if e in edges else 0 for e in all_possible_edges]\n",
    "\n",
    "print(sum(is_con))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78524623",
   "metadata": {},
   "source": [
    "\n",
    "###  model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "114e8d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get training and target data\n",
    "X = np.array(edge_features)\n",
    "y = is_con\n",
    "\n",
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "  X,\n",
    "  y,\n",
    "  test_size = 0.3\n",
    ")\n",
    "\n",
    "# GBC classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# train the model\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c4a54",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b239d2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy :  0.8992460947289282\n",
      "Training Accuracy :  0.9049123545022085\n",
      "MCC Score :  0.30117577179485283\n",
      "Test Confusion Matrix : \n",
      "[[83667  6870]\n",
      " [ 2779  2452]]\n",
      "Test Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95     86446\n",
      "           1       0.47      0.26      0.34      9322\n",
      "\n",
      "    accuracy                           0.90     95768\n",
      "   macro avg       0.70      0.62      0.64     95768\n",
      "weighted avg       0.88      0.90      0.89     95768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "y_true = y_test\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "x_pred = clf.predict(x_train)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "train_acc = accuracy_score(y_train, x_pred)\n",
    "print(\"Testing Accuracy : \", test_acc)\n",
    "print(\"Training Accuracy : \", train_acc)\n",
    "\n",
    "print(\"MCC Score : \", matthews_corrcoef(y_true, y_pred))\n",
    "\n",
    "print(\"Test Confusion Matrix : \")\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "\n",
    "print(\"Test Classification Report : \")\n",
    "print(classification_report(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3d2355",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "972df518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[0.50118293 0.49881707]]\n"
     ]
    }
   ],
   "source": [
    "pred_ft = [(mdl.wv.get_vector(str('42'))+mdl.wv.get_vector(str('210')))]\n",
    "print(clf.predict(pred_ft)[0])\n",
    "\n",
    "print(clf.predict_proba(pred_ft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa8c475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
